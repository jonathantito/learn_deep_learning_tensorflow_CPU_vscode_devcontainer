{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El Hola Mundo del Aprendizaje Profundo con Redes Neuronales\n",
    "Basado en https://colab.research.google.com/github/lmoroney/mlday-tokyo/blob/master/Lab1-Hello-ML-World.ipynb#scrollTo=X9uIpOS2zx7k\n",
    "Originalmente en: https://github.com/lmoroney/mlday-tokyo/blob/master/Lab1-Hello-ML-World.ipynb\n",
    "\n",
    "Como con cualquier primera aplicación, deberías comenzar con algo súper simple que muestre el andamiaje general de cómo funciona tu código.\n",
    "En el caso de crear redes neuronales, el ejemplo que me gusta usar es uno donde aprende la relación entre dos números. Entonces, por ejemplo, si estuvieras escribiendo código para una función como esta, ya conoces las \"reglas\":\n",
    "\n",
    "'''\n",
    "float my_function(float x){\n",
    "    float y = (3 * x) + 1;\n",
    "    return y;\n",
    "}\n",
    "'''\n",
    "Entonces, ¿cómo entrenarías una red neuronal para realizar la tarea equivalente? ¡Usando datos! Al alimentarla con un conjunto de X y un conjunto de Y, debería ser capaz de descubrir la relación entre ellos.\n",
    "Este es obviamente un paradigma muy diferente al que podrías estar acostumbrado, así que vamos a analizarlo pieza por pieza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importaciones\n",
    "Importamos los módulos necesarios de PyTorch: 'torch' para tensores y 'torch.nn' para construir redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir y Compilar la Red Neuronal\n",
    "A continuación, crearemos la red neuronal más simple posible. Tiene 1 capa, y esa capa tiene 1 neurona, y la forma de entrada es solo 1 valor.\n",
    "\n",
    "Definimos la arquitectura de la red neuronal usando una clase llamada 'SimpleNet' que hereda de 'nn.Module'. La red consiste en una sola capa lineal ('nn.Linear') con una \"feature\" de entrada y una de salida.\n",
    "\n",
    "Luego creamos una instancia de la red neuronal llamada model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.layer = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "# Create an instance of the neural network\n",
    "model = SimpleNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora compilamos nuestra Red Neuronal. Al hacerlo, tenemos que especificar 2 funciones, una pérdida y un optimizador.\n",
    "\n",
    "Si has visto mucha matemática para machine learning, aquí es donde generalmente se usa, pero en este caso está muy bien encapsulada en funciones para ti. Pero qué sucede aquí, expliquemos...\n",
    "\n",
    "Sabemos que en nuestra función, la relación entre los números es y=3x+1.\n",
    "\n",
    "Cuando la computadora está tratando de \"aprender\" eso, hace una suposición... tal vez y=10x+10. La función de PÉRDIDA mide las respuestas supuestas contra las respuestas correctas conocidas y mide qué tan bien o mal lo hizo.\n",
    "\n",
    "Luego usa la función de OPTIMIZADOR para hacer otra suposición. Según cómo fue la función de pérdida, intentará minimizar la pérdida. En ese punto, tal vez llegue a algo como y=5x+5, que, aunque todavía es bastante malo, está más cerca del resultado correcto (es decir, la pérdida es menor).\n",
    "\n",
    "Repetirá esto por el número de ÉPOCAS que verás en breve. Pero primero, así es como le decimos que use 'ERROR CUADRÁTICO MEDIO' para la pérdida y 'DESCENSO DE GRADIENTE ESTOCÁSTICO' para el optimizador. Aún no necesitas entender la matemática de estos, ¡pero puedes ver que funcionan! :)\n",
    "\n",
    "Con el tiempo aprenderás las diferentes funciones de pérdida y optimizador apropiadas para diferentes escenarios.\n",
    "\n",
    "Definimos la función de pérdida como el error cuadrático medio ('nn.MSELoss') y el optimizador como descenso de gradiente estocástico ('torch.optim.SGD'). La tasa de aprendizaje (learning rate) se establece en '0.01'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proporcionar los Datos\n",
    "A continuación, introduciremos algunos datos. En este caso estamos tomando 6 x y 6 y. Puedes ver que la relación entre estos es que y=2x-1, entonces donde x = -1, y=-3, etc.\n",
    "\n",
    "Proporcionamos los datos de entrada (xs) y los valores objetivo (ys) como tensores de PyTorch. Usamos unsqueeze(1) para agregar una dimensión extra a los tensores y que coincidan con la forma esperada por la capa lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the data\n",
    "xs = torch.tensor([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=torch.float32).unsqueeze(1)\n",
    "ys = torch.tensor([-2.0, 1.0, 4.0, 7.0, 10.0, 13.0], dtype=torch.float32).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de la Red Neuronal\n",
    "El proceso de entrenar la red neuronal, donde \"aprende\" la relación entre las X y las Y. Aquí es donde pasará por el bucle del que hablamos anteriormente, haciendo una suposición, midiendo qué tan buena o mala es (también conocida como pérdida), usando el optimizador para hacer otra suposición, etc. Lo hará por el número de épocas que especifiques.\n",
    "\n",
    "Comenzamos el bucle de entrenamiento para 50 épocas. En cada época:\n",
    "\n",
    "1.  Realizamos un paso hacia adelante pasando los datos de entrada a través del modelo para obtener las salidas predichas.\n",
    "2. Calculamos la pérdida utilizando la función de pérdida definida.\n",
    "3. Realizamos un paso hacia atrás llamando a loss.backward() para calcular los gradientes.\n",
    "4. Actualizamos los parámetros del modelo utilizando el método step() del optimizador.\n",
    "\n",
    "Finalmente imprimimos la pérdida cada 50 épocas para monitorear el progreso del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.0638\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(xs)\n",
    "    loss = criterion(outputs, ys)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 50 epochs\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, ahora tienes un modelo que ha sido entrenado para aprender la relación entre X e Y. Puedes usar el método model.predict para hacer que determine la Y para una X previamente desconocida. Entonces, por ejemplo, si X = 10, ¿cuál crees que será Y? Adivina antes de ejecutar este código.\n",
    "\n",
    "Después del entrenamiento, hacemos una predicción para un nuevo valor de entrada ('new_x') de 10. Envolvemos el código de predicción con torch.no_grad() para desactivar el cálculo de gradientes durante la inferencia.\n",
    "\n",
    "Finalmente, imprimimos el valor Y predicho para X = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = torch.tensor([10.0], dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.]])\n"
     ]
    }
   ],
   "source": [
    "print(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Y for X = 10: 31.6338\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_y = model(new_x)\n",
    "print(f\"Predicted Y for X = 10: {predicted_y.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podrías haber pensado 31, ¿verdad? Pero terminó siendo un poco más. ¿Por qué crees que es eso?\n",
    "Recuerda que las redes neuronales trabajan con probabilidades, así que dados los datos que alimentamos a la RN con, calculó que hay una probabilidad muy alta de que la relación entre X e Y sea Y=3X+1, pero con solo 6 puntos de datos no podemos estar seguros. Como resultado, el resultado para 10 es muy cercano a 31, pero no necesariamente 31.\n",
    "A medida que trabajes con redes neuronales, verás este patrón recurrente. Casi siempre tratarás con probabilidades, no certezas, y harás un poco de codificación para descubrir cuál es el resultado basado en las probabilidades, particularmente cuando se trata de clasificación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
